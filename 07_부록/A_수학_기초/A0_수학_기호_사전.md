# A0. 수학 기호 사전

> 본 문서는 VLM Book 전체에서 사용되는 수학 기호를 정리한 참조 문서임.

---

## 1. 그리스 문자

### 1.1 소문자

| 기호 | 이름 | 발음 | 딥러닝 용도 |
|:----:|:-----|:-----|:------------|
| α | alpha | 알파 | learning rate, attention weight |
| β | beta | 베타 | momentum 계수, LoRA scaling factor |
| γ | gamma | 감마 | Layer Norm scale parameter |
| δ | delta | 델타 | 오차, 변화량, gradient 신호 |
| ε | epsilon | 엡실론 | 수치 안정성을 위한 작은 상수 (1e-8) |
| η | eta | 에타 | learning rate (α와 혼용) |
| θ | theta | 세타 | 모델 파라미터 전체 집합 |
| λ | lambda | 람다 | 정규화 계수, 고유값 |
| μ | mu | 뮤 | 평균 (mean) |
| σ | sigma | 시그마 | 표준편차, sigmoid 함수 |
| τ | tau | 타우 | temperature parameter |
| φ | phi | 파이 | 활성화 함수, 특징 변환 함수 |
| ω | omega | 오메가 | 가중치, 주파수 (positional encoding) |
| ρ | rho | 로 | 상관계수, RMSprop decay |

### 1.2 대문자

| 기호 | 이름 | 용도 |
|:----:|:-----|:-----|
| Σ | Sigma | 합 (summation) |
| Π | Pi | 곱 (product) |
| Δ | Delta | 변화량 (큰 변화) |
| Θ | Theta | 파라미터 공간 |
| Ω | Omega | 샘플 공간 |

---

## 2. 미적분 기호

### 2.1 미분

| 기호 | 의미 | 예시 | 설명 |
|:----:|:-----|:-----|:-----|
| d/dx | 전미분 | df/dx | f를 x에 대해 미분 |
| ∂ | 편미분 | ∂L/∂W | 다변수 함수의 한 변수에 대한 미분 |
| ∇ | gradient (nabla) | ∇f | 모든 편미분을 벡터로 묶음: [∂f/∂x₁, ∂f/∂x₂, ...] |
| ∇² | Laplacian | ∇²f | 2차 미분의 합 |

**예시: Neural Network에서의 gradient**
```
∂L/∂W = ∂L/∂y × ∂y/∂W

해석:
- L: 손실 함수 (Loss)
- W: 가중치 (Weight)
- y: 출력 (output)
- ∂L/∂W: W가 L에 미치는 영향 (이 값으로 W 업데이트)
```

### 2.2 적분 및 합

| 기호 | 의미 | 예시 | 설명 |
|:----:|:-----|:-----|:-----|
| ∫ | 적분 | ∫f(x)dx | 연속 합 |
| Σ | 합 | Σᵢxᵢ | 이산 합: x₁ + x₂ + ... + xₙ |
| ∏ | 곱 | ∏ᵢxᵢ | 이산 곱: x₁ × x₂ × ... × xₙ |
| lim | 극한 | lim(x→0) f(x) | x가 0에 접근할 때 f(x)의 값 |

---

## 3. 선형대수 기호

### 3.1 행렬/벡터 연산

| 기호 | 의미 | 예시 | 용도 |
|:----:|:-----|:-----|:-----|
| × 또는 @ | 행렬 곱셈 | A × B, A @ B | 일반적인 행렬 곱 |
| ⊙ | element-wise 곱 (Hadamard) | a ⊙ b | 같은 위치 원소끼리 곱 |
| ⊗ | 텐서 곱 (Kronecker) | A ⊗ B | 블록 행렬 생성 |
| · | 내적 (dot product) | a · b = Σᵢaᵢbᵢ | 두 벡터의 유사도 |

**예시: Attention에서의 행렬 곱**
```
scores = Q @ K.T    # [seq_len, d_k] @ [d_k, seq_len] = [seq_len, seq_len]
output = scores @ V # [seq_len, seq_len] @ [seq_len, d_v] = [seq_len, d_v]
```

### 3.2 행렬 변환

| 기호 | 의미 | Python | 설명 |
|:----:|:-----|:-------|:-----|
| Aᵀ 또는 A^T | 전치 (transpose) | A.T | 행과 열 교환 |
| A⁻¹ | 역행렬 | np.linalg.inv(A) | AA⁻¹ = I |
| A† | 유사역행렬 (pseudo-inverse) | np.linalg.pinv(A) | 비정방 행렬의 역 |

### 3.3 행렬 속성

| 기호 | 의미 | Python | 설명 |
|:----:|:-----|:-------|:-----|
| ‖x‖₂ | L2 노름 | np.linalg.norm(x) | √(Σᵢxᵢ²) |
| ‖x‖₁ | L1 노름 | np.sum(np.abs(x)) | Σᵢ|xᵢ| |
| ‖A‖_F | Frobenius 노름 | np.linalg.norm(A, 'fro') | √(ΣᵢΣⱼaᵢⱼ²) |
| det(A) | 행렬식 | np.linalg.det(A) | 행렬의 "부피" |
| tr(A) | 대각합 (trace) | np.trace(A) | Σᵢaᵢᵢ |
| rank(A) | 랭크 | np.linalg.matrix_rank(A) | 독립 행/열 수 |
| diag(a) | 대각 행렬 | np.diag(a) | 벡터를 대각선에 배치 |

---

## 4. 확률/통계 기호

### 4.1 기본 확률

| 기호 | 의미 | 예시 | 설명 |
|:----:|:-----|:-----|:-----|
| P(·) | 확률 | P(X=x) | 사건의 확률 |
| P(A\|B) | 조건부 확률 | P(rain\|cloudy) | B가 주어졌을 때 A의 확률 |
| E[·] | 기댓값 | E[X] = Σᵢxᵢp(xᵢ) | 평균값 |
| Var(·) | 분산 | Var(X) = E[(X-μ)²] | 산포도 |
| Cov(·,·) | 공분산 | Cov(X,Y) | 두 변수의 관계 |

### 4.2 분포 표기

| 기호 | 의미 | 예시 | 설명 |
|:----:|:-----|:-----|:-----|
| ~ | 분포를 따름 | X ~ N(0, 1) | X는 표준정규분포를 따름 |
| N(μ, σ²) | 정규분포 | N(0, 1) | 평균 μ, 분산 σ² |
| U(a, b) | 균등분포 | U(0, 1) | [a, b] 구간에서 균등 |
| Bernoulli(p) | 베르누이 | Bernoulli(0.5) | 이진 결과 |
| Categorical(p) | 카테고리 | softmax 출력 | 다중 클래스 |

### 4.3 정보 이론

| 기호 | 의미 | 수식 | 용도 |
|:----:|:-----|:-----|:-----|
| H(p) | 엔트로피 | -Σ p(x) log p(x) | 불확실성 측정 |
| H(p,q) | Cross-Entropy | -Σ p(x) log q(x) | 분류 손실 함수 |
| D_KL(p‖q) | KL Divergence | Σ p(x) log(p(x)/q(x)) | 분포 차이 |
| I(X;Y) | 상호정보량 | H(X) - H(X\|Y) | 정보 공유량 |

---

## 5. 집합/논리 기호

### 5.1 집합

| 기호 | 의미 | 예시 | 설명 |
|:----:|:-----|:-----|:-----|
| ∈ | 원소 | x ∈ ℝ | x는 실수 |
| ∉ | 원소 아님 | x ∉ ∅ | x는 공집합의 원소가 아님 |
| ⊂ / ⊆ | 부분집합 | A ⊂ B | A는 B의 부분집합 |
| ∪ | 합집합 | A ∪ B | A 또는 B |
| ∩ | 교집합 | A ∩ B | A 그리고 B |
| \ | 차집합 | A \ B | A에서 B 제외 |
| ∅ | 공집합 | - | 원소가 없는 집합 |

### 5.2 수 체계

| 기호 | 의미 | 예시 |
|:----:|:-----|:-----|
| ℕ | 자연수 | {1, 2, 3, ...} |
| ℤ | 정수 | {..., -2, -1, 0, 1, 2, ...} |
| ℝ | 실수 | 모든 실수 |
| ℝⁿ | n차원 실수 공간 | 벡터 공간 |
| ℝᵐˣⁿ | m×n 실수 행렬 | 행렬 공간 |

### 5.3 논리

| 기호 | 의미 | 예시 |
|:----:|:-----|:-----|
| ∀ | 모든 (for all) | ∀x ∈ ℝ |
| ∃ | 존재 (exists) | ∃x such that |
| ∧ | AND | A ∧ B |
| ∨ | OR | A ∨ B |
| ¬ | NOT | ¬A |
| ⟹ | implies | A ⟹ B |
| ⟺ | iff (if and only if) | A ⟺ B |

---

## 6. 딥러닝 특화 기호

### 6.1 변수 표기 규약

| 기호 | 의미 | Shape 예시 | 설명 |
|:----:|:-----|:-----------|:-----|
| x | 입력 | [B, T, D] | 배치, 시퀀스, 차원 |
| y | 정답 | [B, T] 또는 [B, C] | 레이블 |
| ŷ | 예측 | y와 동일 | 모델 출력 |
| W, w | 가중치 | [D_in, D_out] | 학습 파라미터 |
| b | 편향 | [D_out] | 바이어스 |
| h | 은닉 상태 | [B, T, D] | 중간 표현 |
| z | pre-activation | [B, T, D] | 활성화 함수 입력 |
| a | activation | [B, T, D] | 활성화 함수 출력 |

### 6.2 Attention 관련

| 기호 | 의미 | Shape | 설명 |
|:----:|:-----|:------|:-----|
| Q | Query | [B, H, T, d_k] | 질의 행렬 |
| K | Key | [B, H, T, d_k] | 키 행렬 |
| V | Value | [B, H, T, d_v] | 값 행렬 |
| d_model | 모델 차원 | scalar | 전체 임베딩 차원 |
| d_k | Key 차원 | d_model / H | 헤드당 차원 |
| d_v | Value 차원 | d_model / H | 보통 d_k와 동일 |
| H | 헤드 수 | scalar | Multi-Head 개수 |

### 6.3 학습 관련

| 기호 | 의미 | 일반값 | 설명 |
|:----:|:-----|:-------|:-----|
| L, ℒ | 손실 | scalar | Loss 값 |
| B | 배치 크기 | 8~128 | Batch size |
| T | 시퀀스 길이 | 512~32K | Sequence length |
| N | 레이어 수 | 12~96 | Transformer layers |
| E | 에폭 수 | 1~5 | 전체 데이터 반복 |

---

## 7. 수식 해석 예시

### 7.1 Scaled Dot-Product Attention

```
Attention(Q, K, V) = softmax(QK^T / √d_k) × V
```

**단계별 해석:**

1. `Q`: Query 행렬 - "내가 찾고자 하는 것"
2. `K`: Key 행렬 - "정보의 인덱스/라벨"
3. `K^T`: K의 전치 - 행렬 곱을 위한 차원 맞춤
4. `QK^T`: Query와 Key의 유사도 점수 (내적)
5. `√d_k`: 스케일링 - 분산 폭발 방지
6. `softmax(...)`: 확률 분포로 변환 (합=1)
7. `× V`: Value를 확률로 가중합

**Shape 추적:**
```
Q: [B, H, T, d_k]
K: [B, H, T, d_k] → K^T: [B, H, d_k, T]
QK^T: [B, H, T, T]  (attention scores)
softmax: [B, H, T, T]  (attention weights)
V: [B, H, T, d_v]
output: [B, H, T, d_v]
```

### 7.2 Chain Rule (Backpropagation)

```
∂L/∂W = (∂L/∂y) × (∂y/∂W)
```

**해석:**
- `∂L/∂W`: 목표 - W가 L에 미치는 영향
- `∂L/∂y`: 출력 y가 손실에 미치는 영향 (다음 층에서 전파)
- `∂y/∂W`: W가 출력에 미치는 영향 (현재 층 계산)
- 곱하면 전체 영향 계산 (Chain Rule)

**Neural Network 전체:**
```
x → [W₁] → z₁ → [σ] → a₁ → [W₂] → z₂ → [σ] → a₂ → L

∂L/∂W₁ = ∂L/∂a₂ × ∂a₂/∂z₂ × ∂z₂/∂a₁ × ∂a₁/∂z₁ × ∂z₁/∂W₁
```

### 7.3 Cross-Entropy Loss

```
L = -Σᵢ yᵢ log(ŷᵢ)
```

**해석:**
- `yᵢ`: 정답 (one-hot: [0, 0, 1, 0, 0])
- `ŷᵢ`: 예측 확률 (softmax 출력: [0.1, 0.1, 0.6, 0.1, 0.1])
- `log(ŷᵢ)`: 예측의 정보량 (확률 높으면 값 작음)
- `-Σ yᵢ log(ŷᵢ)`: one-hot이므로 정답 위치만 남음
- 결과: `-log(0.6) ≈ 0.51`

---

## 8. Python 코드 대응표

### 8.1 NumPy

| 수학 표기 | NumPy 코드 |
|:----------|:-----------|
| A × B | `np.matmul(A, B)` 또는 `A @ B` |
| A ⊙ B | `A * B` |
| Aᵀ | `A.T` |
| ‖x‖₂ | `np.linalg.norm(x)` |
| Σᵢxᵢ | `np.sum(x)` |
| E[x] | `np.mean(x)` |
| Var(x) | `np.var(x)` |

### 8.2 PyTorch

| 수학 표기 | PyTorch 코드 |
|:----------|:-------------|
| A × B | `torch.matmul(A, B)` 또는 `A @ B` |
| softmax(x) | `F.softmax(x, dim=-1)` |
| log(x) | `torch.log(x)` |
| exp(x) | `torch.exp(x)` |
| ∂L/∂W | `loss.backward()` → `W.grad` |
| ‖x‖₂ | `torch.norm(x)` |

---

## 9. 빠른 참조 카드

### 미분 관련
```
∂: 편미분
∇: gradient (모든 편미분의 벡터)
d/dx: 전미분
```

### 행렬 관련
```
×, @: 행렬 곱
⊙: element-wise 곱
ᵀ: 전치
⁻¹: 역행렬
```

### 확률 관련
```
P(A|B): 조건부 확률
E[X]: 기댓값
~: 분포를 따름
```

### 합/곱 관련
```
Σᵢ: i에 대해 합
∏ᵢ: i에 대해 곱
∫: 적분 (연속 합)
```

---

> 💡 **본문 연결**
> - [1.1 수학적 기초](../../01_딥러닝_Transformer_기초/01_수학적_기초.md)
> - [부록 A1: 선형대수](A1_선형대수.md)
> - [부록 A2: 미적분](A2_미적분.md)
